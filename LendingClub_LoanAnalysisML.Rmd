---
title: "Assignment 2"
author: "Gabriella,Soumya,George,Megan"
date: "3/16/2021"
output: html_document
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Libraries, warning=FALSE, message=FALSE}

library(plyr)
library(tidyverse)
library(lubridate)
library(rpart)
library(broom)
library(caret)
library(shiny)
library(ggplot2)
library(ranger)
library(xgboost)
#install.packages("corrplot")
library(corrplot)
library(glmnet)
library(ROCR)
library(rsample)
library(pROC)
#install.packages("leaps")
library(leaps) #stepwise selection
#install.packages("ROSE")
library(ROSE)

```

### Creation of The Dataframes and Derived Attributes, and re-formating some columns/variables
```{r DF and Derived Attr Creation & Formating, results="hide", warning=FALSE, message=FALSE}

lcdf <- read_csv('lcDataSample5m.csv')
lcdf <- lcdf %>% filter(loan_status=="Fully Paid" | loan_status=="Charged Off")

#Convert last payment to proper date format
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")
lcdf$earliest_cr_line<-paste(lcdf$earliest_cr_line, "-01", sep = "")
lcdf$earliest_cr_line<-parse_date_time(lcdf$earliest_cr_line, "myd")

#Convert emp_length to factor -- with factor levels ordered in a meaningful way
lcdf$emp_length <- factor(lcdf$emp_length, levels=c("n/a", "< 1 year","1 year","2 years", "3 years" ,  "4 years",   "5 years",   "6 years",   "7 years" ,  "8 years", "9 years", "10+ years" ))

#Recode some purpose categories with very few cases to "other"
lcdf$purpose <- fct_recode(lcdf$purpose, other="wedding", other="educational", other="renewable_energy")

#DERIVED ATTRIBUTES/VARIABLES########################################################################

#Borrower History Variable
#We can use the lubridate functions to precisely handle date-times durations
lcdf$borrHistory <- as.duration(lcdf$earliest_cr_line %--% lcdf$issue_d  ) / dyears(1)

#Actual Term Variable
lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1), 3)

#Actual Return Variable
lcdf$actualRet <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

#Annual Return Variable
lcdf$annRet <- ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#table to store important variables to help calcuate profit and loss
#lcProfit <- lcdf %>% group_by(loan_status) %>% summarise(avgInt=mean(int_rate),avgActInt = mean(actualReturn), avgTerm=mean(actualTerm), profitRate=(avgActInt*avgTerm))
#lcProfitCalc

#####################################################################################################
```

### Dropping Variables due to leakage and replacing NA values
```{r Data leakage & NA values}

#These are the variables we will keep for now, others are dropped due to leakage like in the previous assignment. We keep the derived variables so we can use them later for analysis.
lcdf <- lcdf %>% select(c(loan_amnt, int_rate, installment, grade, sub_grade, emp_length, home_ownership, annual_inc, verification_status, loan_status, purpose, dti, earliest_cr_line, collections_12_mths_ex_med, total_rev_hi_lim, acc_open_past_24mths, avg_cur_bal,bc_open_to_buy, bc_util, chargeoff_within_12_mths, delinq_amnt, mo_sin_old_il_acct, mo_sin_old_rev_tl_op, mo_sin_rcnt_rev_tl_op, mo_sin_rcnt_tl, mort_acc, mths_since_recent_bc, mths_since_recent_inq, num_accts_ever_120_pd, num_actv_bc_tl, num_actv_rev_tl, num_bc_sats, num_bc_tl, num_il_tl, num_op_rev_tl, num_rev_accts, num_rev_tl_bal_gt_0, num_sats, num_tl_120dpd_2m, num_tl_30dpd, num_tl_90g_dpd_24m, num_tl_op_past_12m, pct_tl_nvr_dlq, percent_bc_gt_75, pub_rec_bankruptcies, tax_liens, tot_hi_cred_lim, total_bal_ex_mort, total_bc_limit, total_il_high_credit_limit, borrHistory, actualTerm, actualRet, annRet))

#check which columns have any missing values more than 0 but less than 1 
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0 & colMeans(is.na(lcdf))<1]

#replacing missing vals
lcdf<- lcdf %>% replace_na(list(bc_open_to_buy=median(lcdf$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdf$bc_util, na.rm=TRUE) ))

#check if columns still have any missing values 
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0 & colMeans(is.na(lcdf))<1]

#convert all of the columns with character values into factor form
lcdf <- lcdf %>% mutate_if(is.character, as.factor)

```

```{r Creating lcdfTrn & lcdfTst}

#splitting dataset into training and test subsets\
TRNFRACTION=0.5
nr<-nrow(lcdf)

#equal ratio
set.seed(100)
trnIndex<- sample(1:nr, size = round(TRNFRACTION * nr), replace=FALSE)
lcdfTrn <- lcdf[trnIndex, ]
lcdfTst <- lcdf[-trnIndex, ]

```

### Univariate Analysis
Our aim here is to look at the correlation between the independent variables and dependent variables to check if there are any variables that are highly correlated with our dependent variable, "loan_status".
```{r Univariate Analyses from part A, warning=FALSE, message=FALSE}

aucAll<- sapply(lcdf %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response=lcdf$loan_status) 

#Arrange in order
tidy(aucAll) %>% arrange(desc(aucAll))
tidy(aucAll[aucAll > 0.5]) %>% arrange(desc(aucAll[aucAll > 0.5]))

```

## 1. (a) Develop linear (glm) models to predict loan_status. Experiment with different parameter values,  and identify which gives ‘best’ performance. Describe how you determine ‘best’ performance.  How do you handle variable selection?  Experiment with Ridge and Lasso, and show how you vary these parameters, and what performance is  observed.  

```{r glmnet}

#Set loan_status as factor, if "Fully Paid", set as 1, else if "Charged Off", set as 0
yTrn <- factor(if_else(lcdfTrn$loan_status == "Fully Paid", "1","0")) 

#Remove unwanted column(s)
xDTrn <- lcdfTrn %>% select(-loan_status, -actualTerm, -actualRet, -annRet)
set.seed(100)
glmls_cv <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure = "auc")

#Display the values for lambda min and 1se
glmls_cv$lambda.min
glmls_cv$lambda.1se

plot(glmls_cv)

#When comparing lambda.min to lambda.1se you will notice that the number of variables used in lambda.1se decrease by a lot, we may want to choose the "simpler" model, which uses less variables to prevent overfitting.
tidy(coef(glmls_cv, s = glmls_cv$lambda.min))
tidy(coef(glmls_cv, s = glmls_cv$lambda.1se))

#predls = predict(glmls_cv, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)),s="lambda.1se", type="response")
#predsauc <- prediction(predls, lcdfTst$loan_status)
#aucPerf <- performance(predsauc, "auc")
#aucPerf@y.values
#AUC: 0.6894724

#roc_auc <- performance(predsauc, measure = "tpr", x.measure = "fpr")
#plot(roc_auc, main = "ROC curve", colorize = T)
#abline(a = 0, b = 1)


```

```{r glmnet lasso & ridge with diff lambda, warning=FALSE, message=FALSE}

#Experimenting with different alpha and lambda values

#creating the foldid to standardize the iterations
set.seed(100)
foldid_y = sample(1:10,size=length(yTrn),replace=TRUE)

#Alpha = 1 (lasso)##############################################################
set.seed(100)
glmls_cv_lasso <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure = "auc", foldid=foldid_y, alpha = 1)

#Using lambda.1se, a=1
set.seed(100)
predls_lasso = predict(glmls_cv_lasso, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)), s="lambda.1se", type="response")
predsauc_lasso <- prediction(predls_lasso, lcdfTst$loan_status)
aucPerf_lasso <- performance(predsauc_lasso, "auc")
aucPerf_lasso@y.values
#AUC: 0.6898484

#Using lambda.min, a=1
set.seed(100)
predls_lasso2 = predict(glmls_cv_lasso, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)), s="lambda.min", type="response")
predsauc_lasso2 <- prediction(predls_lasso2, lcdfTst$loan_status)
aucPerf_lasso2 <- performance(predsauc_lasso2, "auc")
aucPerf_lasso2@y.values
#AUC: 0.6912735

#Alpha = 0.5 (both)#############################################################
set.seed(100)
glmls_cv_both <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure = "auc", foldid=foldid_y, alpha = 0.5)

#Using lambda.1se, a=0.5
set.seed(100)
predls_both = predict(glmls_cv_both, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)), s="lambda.1se", type="response")
predsauc_both <- prediction(predls_both, lcdfTst$loan_status)
aucPerf_both <- performance(predsauc_both, "auc")
aucPerf_both@y.values
#AUC: 0.6898673

#Using lambda.min, a=0.5
set.seed(100)
predls_both2 = predict(glmls_cv_both, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)), s="lambda.min", type="response")
predsauc_both2 <- prediction(predls_both2, lcdfTst$loan_status)
aucPerf_both2 <- performance(predsauc_both2, "auc")
aucPerf_both2@y.values
#AUC: 0.6912631

#Alpha = 0 (ridge)##############################################################
set.seed(100)
glmls_cv_ridge <- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial", type.measure = "auc", foldid=foldid_y, alpha = 0)

#Using lambda.1se, a=0
set.seed(100)
predls_ridge = predict(glmls_cv_ridge, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)),s="lambda.1se", type="response")
predsauc_ridge <- prediction(predls_ridge, lcdfTst$loan_status)
aucPerf_ridge <- performance(predsauc_ridge, "auc")
aucPerf_ridge@y.values
#AUC: 0.6885912

#Using lambda.min, a=0
set.seed(100)

predls_ridge2 = predict(glmls_cv_ridge, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)),s="lambda.min", type="response")
predsauc_ridge2 <- prediction(predls_ridge2, lcdfTst$loan_status)
aucPerf_ridge2 <- performance(predsauc_ridge2, "auc")
aucPerf_ridge2@y.values
#AUC: 0.6912378

################################################################################

#Listing out all the variables in each model and their coefficients
tidy(coef(glmls_cv_lasso, s = glmls_cv_lasso$lambda.min)) %>% arrange(desc(abs(value)))
tidy(coef(glmls_cv_lasso, s = glmls_cv_lasso$lambda.1se)) %>% arrange(desc(abs(value)))
tidy(coef(glmls_cv_both, s = glmls_cv_both$lambda.min)) %>% arrange(desc(abs(value)))
tidy(coef(glmls_cv_both, s = glmls_cv_both$lambda.1se)) %>% arrange(desc(abs(value)))
tidy(coef(glmls_cv_ridge, s = glmls_cv_ridge$lambda.min)) %>% arrange(desc(abs(value)))
tidy(coef(glmls_cv_ridge, s = glmls_cv_ridge$lambda.1se)) %>% arrange(desc(abs(value)))
```
### Checking the correlation between the variables
``` {r Check Correlation}

xCorr <- xDTrn %>% select_if(is.numeric) %>% cor()
corrTH = 0.7  #threshold
xCorr[upper.tri(xCorr, diag=TRUE)] <- NA
xCorr <- as.data.frame(as.table(xCorr))
xCorr <- na.omit(xCorr) #remove the rows corresponding to NA values
xCorr_th <- xCorr %>% filter(abs(Freq) > corrTH ) #remove the rows with abs(values) < corrTH
xCorr_th <- xCorr_th[order(-abs(xCorr_th$Freq)),] #order by the corr values

#Convert back to matrix form to use with corrPlot
xCorrMat <- xCorr_th %>% pivot_wider(names_from = Var2, values_from = Freq)
xCorrMat<-column_to_rownames(xCorrMat, var="Var1") #convert first column to rownames
corrplot(as.matrix(xCorrMat), is.corr=FALSE, na.label=" ", method="circle")
xCorrMat

```

### Stepwise Selection
``` {r Stepwise Selection}

#default glm model with no variables
set.seed(100)
glm_low <- glm(lcdfTrn$loan_status~1, data=xDTrn, family=binomial())

#glm model using variables from the glmls_cv_lasso with lambda.1se, exclude variables that might cause multicollinearity 
set.seed(100)
glm_full <- glm(lcdfTrn$loan_status~ grade + home_ownership + verification_status + acc_open_past_24mths + dti + mort_acc + emp_length + percent_bc_gt_75 + purpose + mths_since_recent_inq + tot_hi_cred_lim +  total_rev_hi_lim,data=xDTrn,family=binomial())

#Check the variable importance in our glm model
print(varImp(glm_full, scale = TRUE) %>% arrange(desc(varImp(glm_full, scale = TRUE))))

#Forwards Selection
set.seed(100)
glm_forwards = step(glm_low,scope=list(lower=formula(glm_low),upper=formula(glm_full)), direction="forward")
formula(glm_forwards)
#end results: 
#lcdfTrn$loan_status ~ grade + tot_hi_cred_lim + acc_open_past_24mths + dti + verification_status + percent_bc_gt_75 + home_ownership + emp_length + mths_since_recent_inq + mort_acc + total_rev_hi_lim + purpose
#dropped: percent_bc_gt_75, total_rev_hi_lim
#start AIC: 33737.79, end AIC: 31402.55

#Backwards Selection
set.seed(100)
glm_backwards = step(glm_full, direction = "backward") #default direction is backwards
formula(glm_backwards)
#no change in AIC

```

``` {r Final GLM Model}

#glm model with variables left after forwards stepwise selection
set.seed(100)
lcdfglm <- glm(lcdfTrn$loan_status ~ grade + tot_hi_cred_lim + acc_open_past_24mths + 
    dti + verification_status + emp_length + percent_bc_gt_75 + mths_since_recent_inq + mort_acc + total_rev_hi_lim + 
    purpose, data=xDTrn, family=binomial(link=logit))

#Variable importance for glm model with forwards stepwise selection
print(varImp(lcdfglm, scale = TRUE) %>% arrange(desc(varImp(lcdfglm, scale = TRUE))))

```

## (1b) For the linear model, what is the loss function, and link function you use ? (Write the expression for these, and briefly describe). 
```{r Loss Function & Link Function}
#loss log for each data point = -ve log(probabilities)
```

## (1c) Compare performance of models with that of random forests and gradient boosted tree models  (which you developed in your last assignment). 

```{r Compare GLM, RF, xGB}

#GLM/GLMNET#####################################################################

#GLM Model evaluation using prediction AUC on test data
set.seed(100)
predls_glm<-predict(lcdfglm,lcdfTst)
predauc_glm <- prediction(predls_glm, lcdfTst$loan_status)
aucPerf_glm <- performance(predauc_glm, 'auc')
aucPerf_glm@y.values
#AUC: 0.6912813

#GLMNET Model evaluation using prediction AUC on test data
set.seed(100)
predls_lasso = predict(glmls_cv_lasso, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)), s="lambda.1se", type="response")
predsauc_lasso <- prediction(predls_lasso, lcdfTst$loan_status)
aucPerf_lasso <- performance(predsauc_lasso, "auc")
aucPerf_lasso@y.values
#AUC: 0.6915161


#Random Forest##################################################################

rfTrn <- lcdfTrn %>% select(-actualTerm, -actualRet, -annRet)

set.seed(100)
rfModel <- ranger(loan_status ~., data=rfTrn,
                   num.trees =200, importance='permutation', max.depth = 30, 
                   probability =TRUE)
 
#predict for Random Forest
set.seed(100)
predls_rf<-predict(rfModel, lcdfTst, num.trees = 200, type="response")
predsauc_rf <-prediction(predls_rf$predictions[,'Fully Paid'], lcdfTst$loan_status)
aucPerf_rf <-performance(predsauc_rf, "auc")
aucPerf_rf@y.values
#AUC: 0.6721796

#Gradient Boosted Tree Model####################################################

fdum_ls <- dummyVars(~.,data=lcdf%>% select(-loan_status, -actualTerm, -actualRet, -annRet))  
set.seed(100)
dxlcdf <- predict(fdum_ls, (lcdf%>% select(-actualTerm, -actualRet, -annRet)))

levels(lcdf$loan_status)
dylcdf <- class2ind(lcdf$loan_status, drop2nd = FALSE)

fplcdf <- dylcdf[ , 1]  
colcdf <- dylcdf[ , 2]

#training, test subsets
dxlcdfTrn <- dxlcdf[trnIndex,]
colcdfTrn <- colcdf[trnIndex]
dxlcdfTst <- dxlcdf[-trnIndex,]
colcdfTst <- colcdf[-trnIndex]
dxTrn<-xgb.DMatrix(subset(dxlcdfTrn), label=colcdfTrn)
dxTst<-xgb.DMatrix(subset(dxlcdfTst), label=colcdfTst)

set.seed(100)
xgbWatchlist<-list(train = dxTrn, eval= dxTst)

#cross validation on training data to determine best model
set.seed(100)
xgbParam <- list(max_depth= 3, eta = 0.5, objective = "binary:logistic", eval_metric="error", eval_metric= "auc")
set.seed(100)
xgb_lscv <- xgb.cv(xgbParam, dxTrn, nrounds= 500, nfold=5, early_stopping_rounds= 10)
#best iteration
xgb_lscv$best_iteration
#best model
set.seed(100)
xgbModel <- xgb.train(xgbParam, dxTrn, nrounds= xgb_lscv$best_iteration)

#predict on test data
set.seed(100)
predls_xgb<-predict(xgbModel, dxTst)
predauc_xgb <- prediction(predls_xgb, lcdfTst$loan_status)
aucPerf_xgb <- performance(predauc_xgb, 'auc')
aucPerf_xgb@y.values
#AUC: 0.6880209

#ROC Curve Analysis#############################################################
ROCPerf_glm <- performance(predauc_glm, "tpr", "fpr")
plot(ROCPerf_glm)

ROCPerf_rf <-performance(predsauc_rf,  "tpr", "fpr")
plot(ROCPerf_rf, add=TRUE, col="blue")

ROCPerf_xgb <- performance(predauc_xgb, "tpr", "fpr")
plot(ROCPerf_xgb, add=TRUE, col='green')

#adds to previous plot#add a legend
legend('bottomright', c('GLM', 'Random Forest', 'Gradient Boost'), lty=1, col=c('black', 'blue', 'green'))
abline(a=0, b= 1, col="red")

```

## (1d) Examine which variables are found to be important by the best models from the different methods,  and comment on similarities, difference. What do you conclude? 

```{r}

#Variable importance for GLM
print(varImp(lcdfglm, scale = TRUE) %>% arrange(desc(varImp(lcdfglm, scale = TRUE))))

#variable importance for RF
tidy(importance(rfModel)) %>% arrange(desc(importance(rfModel)))

#variable importance for xGB 
xgb.importance(model = xgbModel)

```

## (1e) In developing models above, do you find larger training samples to give better models ? Do you find  balancing the training data examples across classes to give better models ? 

### Creating different split ratios and sampling
```{r Training and Testing Data Ratios & Sampling}

nr<-nrow(lcdf)
#training = 70%, test = 30%
set.seed(100)
trnIndex73<- sample(1:nr, size = round(0.7 * nr), replace=FALSE)
lcdfTrn73 <- lcdf[trnIndex73, ]
lcdfTst73 <- lcdf[-trnIndex73, ]

#Creating separate training datasets that we can experiment with, that are either undersampled on Fully Paid loans, oversampled on Charged Off loans, or a combination of the two.
set.seed(100)
us_lcdfTrn<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action = na.pass, method="under", p=0.5)$data
set.seed(100)
os_lcdfTrn<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action = na.pass, method="over", p=0.5)$data

#Counting the number of observations in each sampled training set
us_lcdfTrn %>% group_by(loan_status) %>% count()
os_lcdfTrn %>% group_by(loan_status) %>% count()

```

### Using 70% Training data, 30% Testing data
``` {r Comparing with 7:3 Split Data, warning=FALSE, message=FALSE}

#GLM/GLMNET#####################################################################

#Set loan_status as factor, if "Fully Paid", set as 1, else if "Charged Off", set as 0
yTrn73 <- factor(if_else(lcdfTrn73$loan_status == "Fully Paid", "1","0")) 

#creating the foldid to standardize the iterations
set.seed(100)
foldid_y73 = sample(1:10,size=length(yTrn73),replace=TRUE)

#remove unwanted column(s)
xDTrn73 <- lcdfTrn73 %>% select(-loan_status, -actualTerm, -actualRet, -annRet)

#cross validation using glmnet
set.seed(100)
glmls_cv_glm73 <- cv.glmnet(data.matrix(xDTrn73), yTrn73, family="binomial", type.measure = "auc", foldid=foldid_y73, alpha = 1)

#glmnet model evaluation using prediction AUC on test data
set.seed(100)
predls_glm73 = predict(glmls_cv_glm73, data.matrix(lcdfTst73 %>% select(-loan_status, -actualTerm, -actualRet, -annRet)),s="lambda.1se", type="response")
predsauc_glm73 <- prediction(predls_glm73, lcdfTst73$loan_status)
aucPerf_glm73 <- performance(predsauc_glm73, "auc")
aucPerf_glm73@y.values
#AUC: 0.6914524

#Random Forest##################################################################

rfTrn73 <- lcdfTrn73 %>% select(-actualTerm, -actualRet, -annRet)

set.seed(100)
rfModel73 <- ranger(loan_status ~., data=rfTrn73,
                   num.trees =200, importance='permutation', max.depth = 30, 
                   probability =TRUE)
 
#predict for Random Forest
set.seed(100)
predls_rf73<-predict(rfModel73, lcdfTst73, num.trees = 200, type="response")
predsauc_rf73 <-prediction(predls_rf73$predictions[,'Fully Paid'], lcdfTst73$loan_status)
aucPerf_rf73 <-performance(predsauc_rf73, "auc")
aucPerf_rf73@y.values
#AUC: 0.6841938

#Gradient Boosted Tree Model####################################################

fdum_ls73 <- dummyVars(~.,data=lcdf%>% select(-loan_status, -actualTerm, -actualRet, -annRet))  
set.seed(100)
dxlcdf73 <- predict(fdum_ls73, lcdf%>% select(-actualTerm, -actualRet, -annRet))

levels(lcdf$loan_status)
dylcdf73 <- class2ind(lcdf$loan_status, drop2nd = FALSE)

fplcdf73 <- dylcdf73[ , 1]  
colcdf73 <- dylcdf73[ , 2]

#training, test subsets
dxlcdfTrn73 <- dxlcdf73[trnIndex73,]
colcdfTrn73 <- colcdf73[trnIndex73]
dxlcdfTst73 <- dxlcdf73[-trnIndex73,]
colcdfTst73 <- colcdf73[-trnIndex73]

dxTrn73<-xgb.DMatrix(subset(dxlcdfTrn73), label=colcdfTrn73)
dxTst73<-xgb.DMatrix(subset(dxlcdfTst73), label=colcdfTst73)

set.seed(100)
xgbWatchlist73<-list(train = dxTrn73, eval= dxTst73)

#cross validation on training data to determine best model
set.seed(100)
xgbParam <- list(max_depth= 3, eta = 0.5, objective = "binary:logistic", eval_metric="error", eval_metric= "auc")
set.seed(100)
xgb_lscv73 <- xgb.cv(xgbParam, dxTrn73, nrounds= 500, nfold=5, early_stopping_rounds= 10)
#best iteration
xgb_lscv73$best_iteration
#best model
set.seed(100)
xgb_ls73 <- xgb.train(xgbParam, dxTrn73, nrounds= xgb_lscv73$best_iteration)

#predict on test data
predls_xgb73<-predict(xgb_ls73, dxTst73)
predauc_xgb73 <- prediction(predls_xgb73, lcdfTst73$loan_status)
aucPerf_xgb73 <- performance(predauc_xgb73, 'auc')
aucPerf_xgb73@y.values
#AUC: 0.6951292

#ROC Curve Analysis#############################################################
ROCPerf_glm73 <- performance(predsauc_glm73, "tpr", "fpr")
plot(ROCPerf_glm73)

ROCPerf_rf73 <-performance(predsauc_rf73,  "tpr", "fpr")
plot(ROCPerf_rf73, add=TRUE, col="blue")

ROCPerf_xgb73 <- performance(predauc_xgb73, "tpr", "fpr")
plot(ROCPerf_xgb73, add=TRUE, col='green')

#adds to previous plot#add a legend
legend('bottomright', c('GLM', 'Random Forest', 'Gradient Boost'), lty=1, col=c('black', 'blue', 'green'))
abline(a=0, b= 1, col="red")

```

### Undersampling on "Fully Paid" cases
``` {r Comparing with Undersampled Data}

#GLM/GLMNET#####################################################################

#Set loan_status as factor, if "Fully Paid", set as 1, else if "Charged Off", set as 0
yTrn_us <- factor(if_else(us_lcdfTrn$loan_status == "Fully Paid", "1","0")) 

#creating the foldid to standardize the iterations
set.seed(100)
foldid_y_us = sample(1:10,size=length(yTrn_us),replace=TRUE)

#remove unwanted column(s)
xDTrn_us <- us_lcdfTrn %>% select(-loan_status, -actualTerm, -actualRet, -annRet)

#cross validation using glmnet
set.seed(100)
glmls_cv_glm_us <- cv.glmnet(data.matrix(xDTrn_us), yTrn_us, family="binomial", type.measure = "auc", foldid=foldid_y_us, alpha = 1)

#glmnet model evaluation using prediction AUC on test data
set.seed(100)
predls_glm_us = predict(glmls_cv_glm_us, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)),s="lambda.1se", type="response")
predsauc_glm_us <- prediction(predls_glm_us, lcdfTst$loan_status)
aucPerf_glm_us <- performance(predsauc_glm_us, "auc")
aucPerf_glm_us@y.values
#AUC: 0.6895806

#Random Forest##################################################################

rfTrn_us <- us_lcdfTrn %>% select(-actualTerm, -actualRet, -annRet)
set.seed(100)
rfModel_us <- ranger(loan_status ~., data=rfTrn_us,
                   num.trees =200, importance='permutation', max.depth = 30, 
                   probability =TRUE)
 
#predict for Random Forest
set.seed(100)
predls_rf_us<-predict(rfModel_us, lcdfTst, num.trees = 200, type="response")
predsauc_rf_us <-prediction(predls_rf_us$predictions[,'Fully Paid'], lcdfTst$loan_status)
aucPerf_rf_us <-performance(predsauc_rf_us, "auc")
aucPerf_rf_us@y.values
#AUC: 0.8342189

#Gradient Boosted Tree Model####################################################

fdum_ls_us <- dummyVars(~.,data=lcdf%>% select(-loan_status, -actualTerm, -actualRet, -annRet))  
dxlcdf_us <- predict(fdum_ls_us, lcdf%>% select(-actualTerm, -actualRet, -annRet))

levels(lcdf$loan_status)
dylcdf_us <- class2ind(lcdf$loan_status, drop2nd = FALSE)

fplcdf_us <- dylcdf_us[ , 1]  
colcdf_us <- dylcdf_us[ , 2]

#training, test subsets
dxlcdfTrn_us <- dxlcdf_us[trnIndex,]
colcdfTrn_us$loan_status <- colcdfTrn_us <- colcdf_us[trnIndex]
dxlcdfTst_us <- dxlcdf_us[-trnIndex,]
colcdfTst_us <- colcdf_us[-trnIndex]

#Undersampling "Fully Paid" cases
weightpos_us = (40511-sum(colcdfTrn_us$loan_status))/sum(colcdfTrn_us$loan_status)
#if Fully Paid, set column value to undersample weight (#Charged Off/#Fully Paid)
colcdfTrn_us$weights_us <- factor(if_else(colcdfTrn_us$loan_status == 1, weightpos_us , 1))

dxTrn_us<-xgb.DMatrix(subset(dxlcdfTrn_us), label=colcdfTrn_us$loan_status, weight=colcdfTrn_us$weights_us)
dxTst_us<-xgb.DMatrix(subset(dxlcdfTst_us), label=colcdfTst_us)

set.seed(100)
xgbWatchlist_us<-list(train = dxTrn_us, eval= dxTst_us)

#cross validation on training data to determine best model
set.seed(100)
xgbParam <- list(max_depth= 3, eta = 0.5, objective = "binary:logistic", eval_metric="error", eval_metric= "auc")
set.seed(100)
xgb_lscv_us <- xgb.cv(xgbParam, dxTrn_us, nrounds= 500, nfold=5, early_stopping_rounds= 10)
#best iteration
xgb_lscv_us$best_iteration
#best model
set.seed(100)
xgb_ls_us <- xgb.train(xgbParam, dxTrn_us, nrounds= xgb_lscv_us$best_iteration)

#predict on test data
predls_xgb_us<-predict(xgb_ls_us, dxTst_us)
predauc_xgb_us <- prediction(predls_xgb_us, lcdfTst$loan_status)
aucPerf_xgb_us <- performance(predauc_xgb_us, 'auc')
aucPerf_xgb_us@y.values
#AUC: 0.6887569

#ROC Curve Analysis#############################################################
ROCPerf_glm_us <- performance(predsauc_glm_us, "tpr", "fpr")
plot(ROCPerf_glm_us)

ROCPerf_rf_us <-performance(predsauc_rf_us,  "tpr", "fpr")
plot(ROCPerf_rf_us, add=TRUE, col="blue")

ROCPerf_xgb_us <- performance(predauc_xgb_us, "tpr", "fpr")
plot(ROCPerf_xgb_us, add=TRUE, col='green')

#adds to previous plot#add a legend
legend('bottomright', c('GLM', 'Random Forest', 'Gradient Boost'), lty=1, col=c('black', 'blue', 'green'))
abline(a=0, b= 1, col="red")

```

## Oversampling on "Charged Off" cases

``` {r Comparing with Oversampled Data}

#GLM/GLMNET#####################################################################

#Set loan_status as factor, if "Fully Paid", set as 1, else if "Charged Off", set as 0
yTrn_os <- factor(if_else(os_lcdfTrn$loan_status == "Fully Paid", "1","0")) 

#creating the foldid to standardize the iterations
set.seed(100)
foldid_y_os = sample(1:10,size=length(yTrn_os),replace=TRUE)

#remove unwanted column(s)
xDTrn_os <- os_lcdfTrn %>% select(-loan_status, -actualTerm, -actualRet, -annRet)

#cross validation using glmnet
set.seed(100)
glmls_cv_glm_os <- cv.glmnet(data.matrix(xDTrn_os), yTrn_os, family="binomial", type.measure = "auc", foldid=foldid_y_os, alpha = 1)

#glmnet model evaluation using prediction AUC on test data
set.seed(100)
predls_glm_os = predict(glmls_cv_glm_os, data.matrix(lcdfTst %>% select(-loan_status, -actualTerm, -actualRet, -annRet)),s="lambda.1se", type="response")
predauc_glm_os <- prediction(predls_glm_os, lcdfTst$loan_status)
aucPerf_glm_os <- performance(predauc_glm_os, "auc")
aucPerf_glm_os@y.values

#Random Forest##################################################################

rfTrn_os <- us_lcdfTrn %>% select(-actualTerm, -actualRet, -annRet)
set.seed(100)
rfModel_os <- ranger(loan_status ~., data=rfTrn_os,
                   num.trees =200, importance='permutation', max.depth = 30, 
                   probability =TRUE)
 
#predict for Random Forest
set.seed(100)
predls_rf_os<-predict(rfModel_os, lcdfTst, num.trees = 200, type="response")
predauc_rf_os <-prediction(predls_rf_os$predictions[,'Fully Paid'], lcdfTst$loan_status)
aucPerf_rf_os <-performance(predauc_rf_os, "auc")
aucPerf_rf_os@y.values
#AUC: 0.6760355

#Gradient Boosted Tree Model####################################################

set.seed(100)
fdum_ls_os <- dummyVars(~.,data=lcdf%>% select(-loan_status, -actualTerm, -actualRet, -annRet))  
dxlcdf_os <- predict(fdum_ls_os, lcdf%>% select(-actualTerm, -actualRet, -annRet))

levels(lcdf$loan_status)
dylcdf_os <- class2ind(lcdf$loan_status, drop2nd = FALSE)

fplcdf_os <- dylcdf_os[ , 1]  
colcdf_os <- dylcdf_os[ , 2]

#training, test subsets
dxlcdfTrn_os <- dxlcdf_os[trnIndex,]
colcdfTrn_os$loan_status <- colcdfTrn_os <- colcdf_os[trnIndex]
dxlcdfTst_os <- dxlcdf_os[-trnIndex,]
colcdfTst_os <- colcdf_os[-trnIndex]

#oversampling "Charged Off" cases
weightneg_os = sum(colcdfTrn_os$loan_status)/(40511-sum(colcdfTrn_os$loan_status))

#if Fully Paid, set column value to undersample weight (#Charged Off/#Fully Paid)
weights_os <- factor(if_else(colcdfTrn_os$loan_status == 0, weightneg_os , 1))
dxTrn_os<-xgb.DMatrix(subset(dxlcdfTrn_os), label=colcdfTrn_os$loan_status, weight=colcdfTrn_os$weights_os)
dxTst_os<-xgb.DMatrix(subset(dxlcdfTst_os), label=colcdfTst_os)

set.seed(100)
xgbWatchlist_os<-list(train = dxTrn_os, eval= dxTst_os)

#cross validation on training data to determine best model
set.seed(100)
xgbParam <- list(max_depth= 3, eta = 0.5, objective = "binary:logistic", eval_metric="error", eval_metric= "auc")
xgb_lscv_os <- xgb.cv(xgbParam, dxTrn_os, nrounds= 500, nfold=5, early_stopping_rounds= 10)
#best iteration
xgb_lscv_os$best_iteration
#best model
set.seed(100)
xgb_ls_os <- xgb.train(xgbParam, dxTrn_os, nrounds= xgb_lscv_os$best_iteration)

#predict on test data
predls_xgb_os<-predict(xgb_ls_os, dxTst_os)
predauc_xgb_os <- prediction(predls_xgb_os, lcdfTst$loan_status)
aucPerf_xgb_os <- performance(predauc_xgb_os, 'auc')
aucPerf_xgb_os@y.values
#AUC: 0.6867181

#ROC Curve Analysis#############################################################
ROCPerf_glm_os <- performance(predauc_glm_os, "tpr", "fpr")
plot(ROCPerf_glm_os)

ROCPerf_rf_os <-performance(predauc_rf_os,  "tpr", "fpr")
plot(ROCPerf_rf_os, add=TRUE, col="blue")

ROCPerf_xgb_os <- performance(predauc_xgb_os, "tpr", "fpr")
plot(ROCPerf_xgb_os, add=TRUE, col='green')

#adds to previous plot#add a legend
legend('bottomright', c('GLM', 'Random Forest', 'Gradient Boost'), lty=1, col=c('black', 'blue', 'green'))
abline(a=0, b= 1, col="red")

```

##2. Develop models to identify loans which provide the best returns.

```{r Best Returns}

#random forest model
rfModel_Ret<-ranger(actualRet~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees=200, importance='permutation')

rfPredRet_trn<-predict(rfModel_Ret, lcdfTrn)

#Performance by deciles
#training data
predRet_Trn<-lcdfTrn%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTrn))$predictions)

predRet_Trn<-predRet_Trn%>% mutate(tile=ntile(-predRet, 10))

predRet_Trn%>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )


#test data
predRet_Tst<-lcdfTst%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>% mutate(predRet=(predict(rfModel_Ret, lcdfTst))$predictions)

predRet_Tst<-predRet_Tst%>% mutate(tile=ntile(-predRet, 10))

predRet_Tst%>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

```{r GLM Model actualRet}
#glm model

xD<-lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualRet)

glmRet_cv<-cv.glmnet(data.matrix(xD), lcdfTrn$actualRet, family="gaussian")

#training data
predRet_Trn<-lcdfTrn%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>% mutate(predRet= predict(glmRet_cv, data.matrix(lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualRet)),s="lambda.min" ) )

predRet_Trn<-predRet_Trn%>% mutate(tile=ntile(-predRet, 10))

predRet_Trn%>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

#test data
predRet_Tst<-lcdfTst%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>% mutate(predRet= predict(glmRet_cv, data.matrix(lcdfTst%>% select(-loan_status, -actualTerm, -annRet, -actualRet)),s="lambda.min" ) )

predRet_Tst<-predRet_Tst%>% mutate(tile=ntile(-predRet, 10))

predRet_Tst%>% group_by(tile) %>% summarise(count=n(), avgpredRet=mean(predRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

```{r GBM Model actualRet}
#gbm model

fdum<-dummyVars(~.,data=lcdf%>% select(-loan_status, -actualTerm, -annRet, -actualRet)) 

dxlcdf<-predict(fdum, lcdf)

dxlcdfTrn<-dxlcdf[trnIndex,]
dxlcdfTst<-dxlcdf[-trnIndex,]

cy <- lcdf$actualRet

cyTrn <- cy[trnIndex]

# Model Building: XGBoost 
param_list = list( objective = "reg:linear", eta = 0.5, gamma=1, max_depth = 3)


dtrn = xgb.DMatrix( data = as.matrix(dxlcdfTrn),  label = cyTrn) 
dtst = xgb.DMatrix( data = as.matrix(dxlcdfTst))

set.seed(100)
# find optimal value of nrounds
xgbcv = xgb.cv(params = param_list, data = dtrn, nrounds = 500, nfold = 5, early_stopping_rounds = 10) 
  
# Training XGBoost model 
xgb_model = xgb.train(data = dtrn,  
                      params = param_list,  
                      nrounds = xgbcv$best_iteration) 

#print(xgb.importance(model = xgb_model))

#training data
predXgbRet_Trn<-lcdfTrn%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>%
mutate( predXgbRet=predict(xgb_model, dtrn ))
predXgbRet_Trn<-predXgbRet_Trn%>% mutate(tile=ntile(-predXgbRet, 10))
predXgbRet_Trn%>% group_by(tile) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

#test data
predXgbRet_Tst<-lcdfTst%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>%
mutate( predXgbRet=predict(xgb_model, dtst ))
predXgbRet_Tst<-predXgbRet_Tst%>% mutate(tile=ntile(-predXgbRet, 10))
predXgbRet_Tst%>% group_by(tile) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```
```{r Comparing models using actualRet}
#comparison of models based on test data
#RMSE
#random forest
rfPred_tst<-predict(rfModel_Ret, lcdfTst)

rf_rmse <- RMSE(lcdfTst$actualRet,rfPred_tst$predictions)


#glm
glmPred_Tst <- predict(glmRet_cv, data.matrix(lcdfTst%>% select(-loan_status, -actualTerm, -annRet, -actualRet)),s="lambda.min" )
glmPred_Trn <- predict(glmRet_cv, data.matrix(lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualRet)),s="lambda.min" )

glm_rmse <- RMSE(lcdfTst$actualRet,glmPred_Tst)


#xgb
xgbPred_Tst <- predict(xgb_model, dtst )
xgbPred_Trn <- predict(xgb_model, dtrn )

xgb_rmse <- RMSE(lcdfTst$actualRet,xgbPred_Tst)

print("RMSE for models")
print(paste("Random forest=",rf_rmse))

print(paste("Glm=",glm_rmse))

print(paste("Boosted=",xgb_rmse))


```

```{r Plots pred vs actual returns}
#Plots predicted vs actual for different models

#random forest
plot ( (predict(rfModel_Ret, lcdfTrn))$predictions, lcdfTrn$actualRet)
plot ( (predict(rfModel_Ret, lcdfTst))$predictions, lcdfTst$actualRet)

#glm
plot ( glmPred_Trn, lcdfTrn$actualRet)
plot ( glmPred_Tst, lcdfTst$actualRet)

#xgb
plot(xgbPred_Trn,lcdfTrn$actualRet)
plot(xgbPred_Tst,lcdfTst$actualRet)

```
##3. Considering results from Questions 1 and 2 above – that is, considering the best model for predicting loan-status and that for predicting loan returns -- how would you select loans for investment? There can be multiple approaches for combining information from the two models - describe your approach, and show performance. How does performance here compare with use of single models?

```{r Predict loan_status and actualRet}
#loan status
xpredTst<-predict(xgbModel, dxTst)
scoreTst_xgb_ls<-lcdfTst%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>% mutate(score=xpredTst)
scoreTst_xgb_ls<-scoreTst_xgb_ls%>% mutate(tile=ntile(-score, 10))
scoreTst_xgb_ls%>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") ) 

#test data
predXgbRet_Tst<-lcdfTst%>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>%
mutate( predXgbRet=predict(xgb_model, dtst ))
predXgbRet_Tst<-predXgbRet_Tst%>% mutate(tile=ntile(-predXgbRet, 10))
predXgbRet_Tst%>% group_by(tile) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```

```{r Method1}
#Method1 - sort returns model ranked on model 1 scores, add (d=1) in code to be replace with top decmil row number from model 2

d=1
pRetSc<-predXgbRet_Tst%>% mutate(poScore=scoreTst_xgb_ls$score)
pRet_d<-pRetSc%>% filter(tile<=d)
pRet_d<-pRet_d%>% mutate(tile2=ntile(-poScore, 20))
pRet_d%>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```

```{r Method 2}
#Method 2 - calculate expReturn = (predicted Actual Return)*(prob of Fully Paid) and sort on this

#considering top d decile from M2
pRet_d<-pRet_d%>% mutate(expRet=predXgbRet*poScore)
pRet_d<-pRet_d%>% mutate(tile2=ntile(-expRet, 20))
pRet_d%>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(predXgbRet), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet), maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
```


##4. As seen in data summaries and your work in the first assignment, higher grade loans are less likely to  default, but also carry lower interest rates; many lower grad loans are fully paid, and these can yield  higher returns. One approach may be to focus on lower grade loans (C and below), and try to identify  those which are likely to be paid off. Develop models from the data on lower grade loans, and check if  this can provide an effective investment approach. Compare performance of models from different  methods (glm, gbm, rf).

```{r lower grade loans}
lg_lcdfTst<-lcdfTst %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')
lg_lcdfTrn<-lcdfTrn %>% filter(grade=='C'| grade=='D'| grade== 'E'| grade== 'F'| grade== 'G')

rf_M1_lg <- ranger(loan_status ~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, actualRet)), num.trees =200, probability=TRUE, importance='permutation')

lg_scoreTstRF <- lg_lcdfTst %>% select(grade, loan_status, actualRet, actualTerm, int_rate) %>% mutate(score=(predict(rf_M1_lg,lg_lcdfTst))$predictions[,"Fully Paid"])
lg_scoreTstRF <- lg_scoreTstRF %>% mutate(tile=ntile(-score, 10))
lg_scoreTstRF %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualRet), minRet=min(actualRet),  maxRet=max(actualRet), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )

```


